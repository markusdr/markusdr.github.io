@inproceedings{dreyer-etal-2023-evaluating,
 abstract = {Neural models for abstractive summarization tend to generate output that is fluent and well-formed but lacks semantic faithfulness, or factuality, with respect to the input documents. In this paper, we analyze the tradeoff between abstractiveness and factuality of generated summaries across multiple datasets and models, using extensive human evaluations of factuality. In our analysis, we visualize the rates of change in factuality as we gradually increase abstractiveness using a decoding constraint, and we observe that, while increased abstractiveness generally leads to a drop in factuality, the rate of factuality decay depends on factors such as the data that the system was trained on. We introduce two datasets with human factuality judgements; one containing 10.2k generated summaries with systematically varied degrees of abstractiveness; the other containing 4.2k summaries from five different summarization models. We propose new factuality metrics that adjust for the degree of abstractiveness, and we use them to compare the abstractiveness-adjusted factuality of previous summarization works, providing baselines for future work.},
 address = {Dubrovnik, Croatia},
 author = {Dreyer, Markus  and
Liu, Mengwen  and
Nan, Feng  and
Atluri, Sandeep  and
Ravi, Sujith},
 booktitle = {Findings of the Association for Computational Linguistics: EACL 2023},
 doi = {10.18653/v1/2023.findings-eacl.156},
 editor = {Vlachos, Andreas  and
Augenstein, Isabelle},
 month = {May},
 pages = {2089--2105},
 publisher = {Association for Computational Linguistics},
 title = {Evaluating the Tradeoff Between Abstractiveness and Factuality in Abstractive Summarization},
 url = {https://aclanthology.org/2023.findings-eacl.156},
 year = {2023}
}

