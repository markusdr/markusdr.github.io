@inproceedings{zhang-etal-2023-enhancing,
 abstract = {Information extraction (IE) and summarization are closely related, both tasked with presenting a subset of the information contained in a natural language text. However, while IE extracts structural representations, summarization aims to abstract the most salient information into a generated text summary -- thus potentially encountering the technical limitations of current text generation methods (e.g., hallucination). To mitigate this risk, this work uses structured IE graphs to enhance the abstractive summarization task. Specifically, we focus on improving Multi-Document Summarization (MDS) performance by using cross-document IE output, incorporating two novel components: (1) the use of auxiliary entity and event recognition systems to focus the summary generation model; (2) incorporating an alignment loss between IE nodes and their text spans to reduce inconsistencies between the IE graphs and text representations. Operationally, both the IE nodes and corresponding text spans are projected into the same embedding space and pairwise distance is minimized. Experimental results on multiple MDS benchmarks show that summaries generated by our model are more factually consistent with the source documents than baseline models while maintaining the same level of abstractiveness.},
 address = {Dubrovnik, Croatia},
 author = {Zhang, Zixuan  and
Elfardy, Heba  and
Dreyer, Markus  and
Small, Kevin  and
Ji, Heng  and
Bansal, Mohit},
 booktitle = {Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
 doi = {10.18653/v1/2023.eacl-main.124},
 editor = {Vlachos, Andreas  and
Augenstein, Isabelle},
 month = {May},
 pages = {1696--1707},
 publisher = {Association for Computational Linguistics},
 title = {Enhancing Multi-Document Summarization with Cross-Document Graph-based Information Extraction},
 url = {https://aclanthology.org/2023.eacl-main.124},
 year = {2023}
}

